---
title: "Principal Component Analysis, Principal Component Regression and Partial Least Squares Regression"
output: 
    bookdown::pdf_document2:
       toc: false
       number_sections: false
       extra_dependencies: ["flafter"]
header-includes: 
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{subfig}
  - \usepackage{graphicx}
  - \usepackage{multicol}
  - \newcommand{\btwocol}{\begin{multicols}{2}}
  - \newcommand{\etwocol}{\end{multicols}}
urlcolor: blue
geometry: "left=1cm,right=1cm,top=1cm,bottom=1.5cm"
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = ""
)
```


***Consider the Hitters dataset from the ISLR package in R. It consists of 20 variables measured on 263 major league baseball players (after removing those with missing data). Salary is the response variable and the remaining 19 are predictors. Some of the predictor variables are categorical with two classes. The goal is to perform a principal components analysis (PCA) of the data***

a) Standardization dataset is necessary as it removes the biases in the original variables. For example, when the data for each variable is collected on different units. The standardized variables will be unitless and have a similar variance.In the given dataset Hitters, the variables are measured in different scales. Hence it is a good idea to standardize the variables.

&nbsp;

```{r echo=TRUE}
library(ISLR)
str(Hitters)
Hitters <- na.omit(Hitters)
dim(Hitters)
```

&nbsp;

b) Based on Table 1 it can be observed that the first 4 principle components accounted for 80% of the total variance.4 principle components seem to be explained most of the variance and therefore 4 principle components are recommended.Screeplot for PCs is shown in **Figure** \@ref(fig:q1b) and it confirms the above results.

&nbsp;

```{r echo=TRUE}
Hitters.X<-Hitters[-19]
Hitters.X$League<-ifelse(Hitters.X$League=="A",0,1)
Hitters.X$Division<-ifelse(Hitters.X$Division=="E",0,1)
Hitters.X$NewLeague<-ifelse(Hitters.X$NewLeague=="A",0,1)
```

```{r echo=TRUE}
#Part b)
pca.Hit <- prcomp(Hitters.X, center = T, scale = T)
```


```{r,results="asis", echo=TRUE}
library(xtable)
options(xtable.comment=FALSE)
xtable(summary(pca.Hit),caption = "Proportion of Variance and Cumulative Proportions")
```

```{r q1b,echo=TRUE,fig.height=3, fig.width=3, fig.cap="\\textit{Scree plot for Principal components of Hitters Data}"}
par(mar = c(3.8, 3.8,1,1))
screeplot(pca.Hit, type="lines",main="")
```

```{r,results="asis", echo=TRUE}
options(xtable.comment=FALSE)
print(xtable(pca.Hit$rotation[,1:4],caption = "Loading matrix")
,table.placement="H")
```

&nbsp;

c) The correlation between the first two principle components and the standardized variables are given in Table 2. According to the **Figure** \@ref(fig:q1c) we can see that variables  predictors Years, CHmRun, CRBI are correlated and heavily loaded on PCA1. Moreover predictors like Runs, RB1, Errors, Assist are heavily on PCA2. Also, it can be observed that most of the observations corresponds to a score that ranges from -5 to 5 with respect to both principle components. Observations Ted Simons , Pete Rose seems belongs to PCA1 as those observations corresponds to lower values of PCA2 and higher values of PCA1.

&nbsp;

```{r,results="asis", echo=TRUE}
# Standardize quantitative variables
std.Hit=scale(Hitters.X)
cor.Hit=cor(pca.Hit$x[,c(1,2)],std.Hit)
xtable(cor.Hit[,1:8],digits=c(0,4,4,4,4,4,4,4,4))
xtable(cor.Hit[,9:16],digits=c(0,4,4,4,4,4,4,4,4), caption = "Correlation of the standardized quantitative variables with the first two components ")
```

```{r q1c,echo=TRUE,fig.height=3, fig.width=7.5, fig.cap="\\textit{Biplots for PCA of Hitters Data}"}
par(mar = c(3.8, 3.8,1,1))
# Display a biplot the results (shows both pc scores and loading vectors) 
biplot(pca.Hit, scale=0)
```

&nbsp;

d)  Multiple linear regression model using all predictors was performed and calculated test MSE using LOOCV.

&nbsp;

```{r echo=TRUE}
set.seed(1)
library(caret)
#specify the cross-validation method
ctrl <- trainControl(method = "LOOCV")

#fit a regression model and use LOOCV to evaluate performance
linear.fit <- train(log(Salary)~., data = Hitters, method = "lm", trControl = ctrl)

#view summary of LOOCV               
a.mse<-as.numeric(linear.fit$results[2])^2
```

&nbsp;

e) PCR was performed and M chosen optimally via LOOCV. $M=17$ was chosen as the optimal M as it gives the lowest MSE. **Figure** \@ref(fig:q3bc) shows the validation plot.

&nbsp;

```{r echo=TRUE}
#Part b)
library(pls)
# Fit PCR
set.seed(1)
pcr.fit <- pcr(log(Salary) ~ ., data = Hitters, scale = TRUE, validation = "LOO")

# Get MSE 
M1<-which.min(MSEP(pcr.fit)$val[1, 1,])
MSEP(pcr.fit)
```

&nbsp;

f) PLS was performed and M chosen optimally via LOOCV. $M=13$ was chosen as the optimal M as it gives the lowest MSE. **Figure** \@ref(fig:q3bc) shows the validation plot.

&nbsp;

```{r echo=TRUE}
#Partc)
library(pls)
# Fit PCR
set.seed(1)
pls.fit <- plsr(log(Salary) ~ ., data = Hitters, scale = TRUE, validation = "LOO")

# Get MSE 
M2<-which.min(MSEP(pls.fit)$val[1, 1,])
MSEP(pls.fit)
```

```{r q3bc,echo=TRUE,fig.height=3, fig.width=7.5, fig.cap="\\textit{Validation plots for PCR and PLS}"}
par(mfrow=c(1,2))
par(mar = c(3.8, 3.8,1,1))
validationplot(pcr.fit, val.type = "MSEP",main="PCR")
validationplot(pls.fit, val.type = "MSEP",main="PLS")
```

&nbsp;

g) Ridge regression was performed and penalty parameter chosen optimally via LOOCV. Best $\lambda$ value is 0.07286764. **Figure** \@ref(fig:q1ef) shows plot of test MSE vs $\log(\lambda)$. 

&nbsp;

```{r, echo=TRUE}
#Part d)
# Create response vector and the design matrix (without the first column of 1s) 
y <- log(Hitters$Salary)
x <- model.matrix(log(Salary) ~ ., Hitters)[, -1]
n<-nrow(Hitters)
grid <- 10^seq(10, -2, length = 100)
```

```{r, echo=TRUE}
# Use cross-validation to estimate test MSE from training data
library(glmnet)
set.seed(1)
cv.out <- cv.glmnet(x,y, alpha = 0,nfolds=n,grouped = FALSE)

# Find the best value of lambda
bestlam <- cv.out$lambda.min
bestlam

# Test MSE for the best value of lambda
ridge.mod <- glmnet(x, y, alpha = 0, lambda = grid)
ridge.pred <- predict(ridge.mod, s = bestlam, newx =x)
d.mse<-mean((ridge.pred - y)^2)
```

```{r q1ef,echo=TRUE,fig.height=2.5, fig.width=3, fig.cap="\\textit{plot of test MSE vs log(lambda) using ridge regression}"}

par(mar = c(3.8, 3.8,1,1))
plot(cv.out)
```

&nbsp;

h) According to the following table Ridge regression model has the lowest MSE. Moreover PCR and PSL gives fairly similar MSE rate and parameter estimates. Therefore we can select model chosen from the ridge regression as the best model.

\begin{table}[H]
\centering
\begin{tabular}{lrrrr}
\hline
 & Linear regression &  PCR & PLS &  Ridge regression\\
\hline
Test MSE & 0.4214 & 0.4138 &  0.4148 & 0.3607\\
\hline
\end{tabular}
\caption{\textit{Summary of test MSE}}
\end{table}



